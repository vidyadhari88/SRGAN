{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_project3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtmTiiwVA746",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "c1401aa1-466b-4a61-d357-7fa50c039e3f"
      },
      "source": [
        "!nvidia-smi\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May  9 09:35:54 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    89W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI6EmA2bBDk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61e48b6b-ff17-4cbf-9755-f62b78ef2b7e"
      },
      "source": [
        "# importing libraries\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
        "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import add\n",
        "from keras.applications import VGG19\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwK6Ei2LCaOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_block_gen(model, kernal_size, filters, strides):\n",
        "    gen = model\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "\n",
        "    model = add([gen, model])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# def plotLoss(epoch):\n",
        "#     plt.figure(figsize=(10, 8))\n",
        "#     plt.plot(dLosses, label='Discriminitive loss')\n",
        "#     plt.plot(gLosses, label='Generative loss')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.legend()\n",
        "#     plt.savefig('images/gan_cnn_64x64/dcgan_%d_loss_epoch.png' % epoch)\n",
        "    \n",
        "def up_sampling_block(model, kernal_size, filters, strides):\n",
        "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = UpSampling2D(size = 2)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def discriminator_block(model, filters, kernel_size, strides):\n",
        "\n",
        "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    gan = Model(inputs=gan_input, outputs=[x,gan_output])\n",
        "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "\n",
        "    return gan\n",
        "\n",
        "\n",
        "def datagen(batchSize,filesList,filePath):\n",
        "    while(True):\n",
        "        files = np.random.choice(filesList,batchSize,replace=False)\n",
        "        X_train_HR = []\n",
        "        X_train_LR = []\n",
        "        for file in files:\n",
        "            image = cv2.imread(filePath + \"/\" + file)\n",
        "#             print(filePath + \"/\" + file)\n",
        "#             print(image)\n",
        "            image_HR = cv2.resize(image,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "            image_HR = image_HR / 255.0\n",
        "            X_train_HR.append(image_HR)\n",
        "            \n",
        "            image_LR = cv2.resize(image,(56,56),interpolation = cv2.INTER_CUBIC)\n",
        "            image_LR = image_LR / 255.0\n",
        "            \n",
        "            X_train_LR.append(image_LR)\n",
        "            \n",
        "        X_train_HR = np.array(X_train_HR)\n",
        "        X_train_LR = np.array(X_train_LR)\n",
        "        yield X_train_LR,X_train_HR\n",
        "          \n",
        "\n",
        "def plotGeneratedImages(epoch,datagen,generator, examples=100, dim=(1, 1), figsize=(2, 2)):\n",
        "    randomDim = 100\n",
        "    low,hit = next(datagen)\n",
        "    generatedImages = generator.predict(low)\n",
        "    fig = plt.figure(figsize=(10,1))\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "    for i in range(batch_count):\n",
        "        ax = fig.add_subplot(1, 10, i + 1, xticks=[], yticks=[])\n",
        "        ax.imshow(generatedImages[i])\n",
        "    fol = 'images/gan_cnn_64x64/images/'\n",
        "    if not os.path.exists(fol):\n",
        "        os.makedirs(fol)\n",
        "    plt.savefig(fol+'random_{:05d}.png'.format(epoch))\n",
        "    \n",
        "    r,c=2,2\n",
        "    # Save generated images and the high resolution originals\n",
        "    titles = ['Generated', 'Original']\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for row in range(r):\n",
        "        for col, image in enumerate([generatedImages, hit]):\n",
        "            axs[row, col].imshow(image[row])\n",
        "            axs[row, col].set_title(titles[col])\n",
        "            axs[row, col].axis('off')\n",
        "        cnt += 1\n",
        "    fig.savefig(fol+'random_{:05d}_comparison.png'.format(epoch))\n",
        "    plt.close()\n",
        "    \n",
        "    for i in range(r):\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(low[i])\n",
        "        fig.savefig(fol+'random_{:05d}_low_res.png'.format(epoch))\n",
        "        plt.close()\n",
        "    \n",
        "    \n",
        "def saveModels(epoch,generator,discriminator):\n",
        "    fol = 'models/gan_cnn_64x64/'\n",
        "    if not os.path.exists(fol):\n",
        "        os.makedirs(fol)\n",
        "    generator.save(fol+'dcgan_generator_epoch_%d.h5' % epoch)\n",
        "    discriminator.save(fol+'dcgan_discriminator_epoch_%d.h5' % epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXr4V-dcDIky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator():\n",
        "    def __init__(self, noise_shape):\n",
        "        self.noise_shape = noise_shape\n",
        "        \n",
        "    def gen(self):\n",
        "        gen_Input = Input(shape = self.noise_shape)\n",
        "        \n",
        "        \n",
        "        model = Conv2D(filters = 64,kernel_size = 9 ,strides=1,padding = \"same\") (gen_Input)\n",
        "        model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "        \n",
        "        for i in range(16):\n",
        "            model = res_block_gen(model,3,64,1)\n",
        "            \n",
        "            \n",
        "        for i in range(2):\n",
        "            model = up_sampling_block(model,3,256,1)\n",
        "        \n",
        "        model = Conv2D(filters = 3,kernel_size=9,strides=1,padding=\"same\")(model)\n",
        "        model = Activation('tanh')(model)\n",
        "        \n",
        "        generator_model = Model(inputs = gen_Input, outputs = model)\n",
        "        \n",
        "        return generator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LecFEGutDgeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Disciminator():\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "        \n",
        "        \n",
        "    def disc(self):\n",
        "        disc_Input = Input(shape = self.image_shape)\n",
        "        \n",
        "        model = Conv2D(filters = 64,kernel_size = 3 ,strides=1,padding = \"same\") (disc_Input)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        \n",
        "        model = discriminator_block(model, 64, 3, 2)\n",
        "        model = discriminator_block(model, 128, 3, 1)\n",
        "        model = discriminator_block(model, 128, 3, 2)\n",
        "        model = discriminator_block(model, 256, 3, 1)\n",
        "        model = discriminator_block(model, 256, 3, 2)\n",
        "        model = discriminator_block(model, 512, 3, 1)\n",
        "        model = discriminator_block(model, 512, 3, 2)\n",
        "        \n",
        "        model = Flatten()(model)\n",
        "        \n",
        "        model = Dense(1024)(model)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        model = Dense(1)(model)\n",
        "        model = Activation('softmax')(model)\n",
        "        \n",
        "        disciminator_model = Model(inputs = disc_Input,output = model)\n",
        "        \n",
        "        \n",
        "        return disciminator_model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQbBb4vZDlGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    # computes VGG loss or content loss\n",
        "    def vgg_loss(self, y_true, y_pred):\n",
        "    \n",
        "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
        "        vgg19.trainable = False\n",
        "        # Make trainable as False\n",
        "        for l in vgg19.layers:\n",
        "            l.trainable = False\n",
        "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "        model.trainable = False\n",
        "    \n",
        "        return K.mean(K.square(model(y_true) - model(y_pred)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxJp1E7-DxtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filePath_train_HR = '/home/jupyter/AML_Proj_3/Flickr2K/Flickr2K/'\n",
        "\n",
        "\n",
        "train_HR = [f for f in os.listdir(filePath_train_HR) ]\n",
        "#valid_HR = [f for f in os.listdir(filePath_val_HR) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQj2xhhCLg4Y",
        "colab_type": "code",
        "outputId": "e47eaecd-e988-4c17-c5be-e94821346a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "len(train_HR)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-87c58e4c1fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_HR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_HR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmFvJ9tbGfO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cd93fe0e-a3ea-411a-b3bf-3bccd9f6966d"
      },
      "source": [
        "image_HR_shape = (224,224,3)\n",
        "image_SR_shape = (56,56,3)\n",
        "optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "# optimizer2 = Adam(0.02, 0.5)\n",
        "no_of_epoch =20000\n",
        "batch_count = 4\n",
        "d_loss = []\n",
        "g_loss = []"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22sSYd3aGkvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    \n",
        "    loss = VGG(image_HR_shape)\n",
        "     \n",
        "    #making the generator network to predict image by supplying low resolution input\n",
        "    \n",
        "    generator = Generator(image_SR_shape).gen()\n",
        "    discriminator = Disciminator(image_HR_shape).disc()\n",
        "    \n",
        "   # vgg_optimizer = loss.get_optimizer()\n",
        "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "    \n",
        "    \n",
        "    gan = get_gan_network(discriminator, image_SR_shape, generator, optimizer, loss.vgg_loss)\n",
        "    datagenObj = datagen(batch_count,train_HR,filePath_train_HR)\n",
        "    \n",
        "    \n",
        "    for e in range(1,no_of_epoch):\n",
        "        if e%100==0:\n",
        "            print(e)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            lr_img,hr_img = next(datagenObj)\n",
        "            fake_img = generator.predict(lr_img)\n",
        "            \n",
        "            #inputDisc = np.concatenate([hr_img,fake_img])\n",
        "            \n",
        "            real_data_Y = np.ones(batch_count) - np.random.random_sample(batch_count)*0.2\n",
        "            fake_data_Y = np.random.random_sample(batch_count)*0.2\n",
        "            \n",
        "            # training the disciminator\n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            d_loss_real = discriminator.train_on_batch(hr_img, real_data_Y)\n",
        "            d_loss_fake = discriminator.train_on_batch(fake_img, fake_data_Y)\n",
        "            dloss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "           # dloss = discriminator.train_on_batch(inputDisc, target_value)\n",
        "            \n",
        "            #training the generator\n",
        "            #generator is frozen\n",
        "            lr_img,hr_img = next(datagenObj)\n",
        "            target_value = np.ones(batch_count)\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(lr_img, [hr_img,target_value])\n",
        "        \n",
        "        d_loss.append(dloss)\n",
        "        g_loss.append(gan_loss)\n",
        "        \n",
        "        if e == 1 or e % 100 == 0:\n",
        "            saveModels(e,generator,discriminator)\n",
        "            plotGeneratedImages(e,datagenObj,generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYZkpowt2H8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "4d47f24b-ae50-4296-e8f7-2557a42415db"
      },
      "source": [
        "train()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-2c2fc155c45a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gan_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_SR_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdatagenObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_HR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilePath_train_HR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_HR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlT069WnHq17",
        "colab_type": "code",
        "outputId": "3b951e9a-4cb1-4404-9ff6-68eeb214e6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(g_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09295985, 0.09295985, 1.1920933e-07], [0.07714353, 0.07714353, 1.1920933e-07], [0.05764451, 0.05764451, 1.1920933e-07], [0.05396224, 0.05396224, 1.1920933e-07]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzFZ4fykk66q",
        "colab_type": "code",
        "outputId": "5b3ab6cd-417a-48ea-ef5f-b3b77e9c2f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(d_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8.443008422851562, 7.83233118057251, 7.593783855438232, 7.850303649902344]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bXyPT9ClARz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
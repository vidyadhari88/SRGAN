{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML_proj3_v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtmTiiwVA746",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI6EmA2bBDk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
        "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import add\n",
        "from keras.applications import VGG19\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwK6Ei2LCaOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_block_gen(model, kernal_size, filters, strides):\n",
        "    gen = model\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "\n",
        "    model = add([gen, model])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# def plotLoss(epoch):\n",
        "#     plt.figure(figsize=(10, 8))\n",
        "#     plt.plot(dLosses, label='Discriminitive loss')\n",
        "#     plt.plot(gLosses, label='Generative loss')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.legend()\n",
        "#     plt.savefig('images/gan_cnn_64x64/dcgan_%d_loss_epoch.png' % epoch)\n",
        "    \n",
        "def up_sampling_block(model, kernal_size, filters, strides):\n",
        "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = UpSampling2D(size = 2)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def discriminator_block(model, filters, kernel_size, strides):\n",
        "\n",
        "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    gan = Model(inputs=gan_input, outputs=[x,gan_output])\n",
        "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "\n",
        "    return gan\n",
        "\n",
        "\n",
        "def datagen(batchSize,filesList,filePath):\n",
        "    while(True):\n",
        "        files = np.random.choice(filesList,batchSize,replace=False)\n",
        "        X_train_HR = []\n",
        "        X_train_LR = []\n",
        "        for file in files:\n",
        "            image = cv2.imread(filePath + \"/\" + file)\n",
        "#             print(filePath + \"/\" + file)\n",
        "#             print(image)\n",
        "            image_HR = cv2.resize(image,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "            image_HR = image_HR / 255.0\n",
        "            X_train_HR.append(image_HR)\n",
        "            \n",
        "            image_LR = cv2.resize(image,(56,56),interpolation = cv2.INTER_CUBIC)\n",
        "            image_LR = image_LR / 255.0\n",
        "            \n",
        "            X_train_LR.append(image_LR)\n",
        "            \n",
        "        X_train_HR = np.array(X_train_HR)\n",
        "        X_train_LR = np.array(X_train_LR)\n",
        "        yield X_train_LR,X_train_HR\n",
        "          \n",
        "\n",
        "def plotGeneratedImages(epoch,datagen,generator, examples=100, dim=(1, 1), figsize=(2, 2)):\n",
        "    randomDim = 100\n",
        "    low,hit = next(datagen)\n",
        "    generatedImages = generator.predict(low)\n",
        "    fig = plt.figure(figsize=(10,1))\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "    for i in range(batch_count):\n",
        "        ax = fig.add_subplot(1, 10, i + 1, xticks=[], yticks=[])\n",
        "        ax.imshow(generatedImages[i])\n",
        "    fol = 'images/gan_cnn_64x64/images/'\n",
        "    if not os.path.exists(fol):\n",
        "        os.makedirs(fol)\n",
        "    plt.savefig(fol+'random_{:05d}.png'.format(epoch))\n",
        "    \n",
        "    r,c=2,2\n",
        "    # Save generated images and the high resolution originals\n",
        "    titles = ['Generated', 'Original']\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for row in range(r):\n",
        "        for col, image in enumerate([generatedImages, hit]):\n",
        "            axs[row, col].imshow(image[row])\n",
        "            axs[row, col].set_title(titles[col])\n",
        "            axs[row, col].axis('off')\n",
        "        cnt += 1\n",
        "    fig.savefig(fol+'random_{:05d}_comparison.png'.format(epoch))\n",
        "    plt.close()\n",
        "    \n",
        "    for i in range(r):\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(low[i])\n",
        "        fig.savefig(fol+'random_{:05d}_low_res.png'.format(epoch))\n",
        "        plt.close()\n",
        "    \n",
        "    \n",
        "def saveModels(epoch,generator,discriminator):\n",
        "    fol = 'models/gan_cnn_64x64/'\n",
        "    if not os.path.exists(fol):\n",
        "        os.makedirs(fol)\n",
        "    generator.save(fol+'dcgan_generator_epoch_%d.h5' % epoch)\n",
        "    discriminator.save(fol+'dcgan_discriminator_epoch_%d.h5' % epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXr4V-dcDIky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator():\n",
        "    def __init__(self, noise_shape):\n",
        "        self.noise_shape = noise_shape\n",
        "        \n",
        "    def gen(self):\n",
        "        gen_Input = Input(shape = self.noise_shape)\n",
        "        \n",
        "        \n",
        "        model = Conv2D(filters = 64,kernel_size = 9 ,strides=1,padding = \"same\") (gen_Input)\n",
        "        model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "        \n",
        "        for i in range(16):\n",
        "            model = res_block_gen(model,3,64,1)\n",
        "            \n",
        "            \n",
        "        for i in range(2):\n",
        "            model = up_sampling_block(model,3,256,1)\n",
        "        \n",
        "        model = Conv2D(filters = 3,kernel_size=9,strides=1,padding=\"same\")(model)\n",
        "        model = Activation('tanh')(model)\n",
        "        \n",
        "        generator_model = Model(inputs = gen_Input, outputs = model)\n",
        "        \n",
        "        return generator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LecFEGutDgeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Disciminator():\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "        \n",
        "        \n",
        "    def disc(self):\n",
        "        disc_Input = Input(shape = self.image_shape)\n",
        "        \n",
        "        model = Conv2D(filters = 64,kernel_size = 3 ,strides=1,padding = \"same\") (disc_Input)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        \n",
        "        model = discriminator_block(model, 64, 3, 2)\n",
        "        model = discriminator_block(model, 128, 3, 1)\n",
        "        model = discriminator_block(model, 128, 3, 2)\n",
        "        model = discriminator_block(model, 256, 3, 1)\n",
        "        model = discriminator_block(model, 256, 3, 2)\n",
        "        model = discriminator_block(model, 512, 3, 1)\n",
        "        model = discriminator_block(model, 512, 3, 2)\n",
        "        \n",
        "        model = Flatten()(model)\n",
        "        \n",
        "        model = Dense(1024)(model)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        model = Dense(1)(model)\n",
        "        model = Activation('softmax')(model)\n",
        "        \n",
        "        disciminator_model = Model(inputs = disc_Input,output = model)\n",
        "        \n",
        "        \n",
        "        return disciminator_model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQbBb4vZDlGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    # computes VGG loss or content loss\n",
        "    def vgg_loss(self, y_true, y_pred):\n",
        "    \n",
        "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
        "        vgg19.trainable = False\n",
        "        # Make trainable as False\n",
        "        for l in vgg19.layers:\n",
        "            l.trainable = False\n",
        "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "        model.trainable = False\n",
        "    \n",
        "        return K.mean(K.square(model(y_true) - model(y_pred)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxJp1E7-DxtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filePath_train_HR = '/home/jupyter/AML_Proj_3/Flickr2K/Flickr2K/'\n",
        "\n",
        "\n",
        "train_HR = [f for f in os.listdir(filePath_train_HR) ]\n",
        "#valid_HR = [f for f in os.listdir(filePath_val_HR) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQj2xhhCLg4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_HR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmFvJ9tbGfO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_HR_shape = (224,224,3)\n",
        "image_SR_shape = (56,56,3)\n",
        "optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "# optimizer2 = Adam(0.02, 0.5)\n",
        "no_of_epoch =20000\n",
        "batch_count = 4\n",
        "d_loss = []\n",
        "g_loss = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22sSYd3aGkvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    \n",
        "    loss = VGG(image_HR_shape)\n",
        "     \n",
        "    #making the generator network to predict image by supplying low resolution input\n",
        "    \n",
        "    generator = Generator(image_SR_shape).gen()\n",
        "    discriminator = Disciminator(image_HR_shape).disc()\n",
        "    \n",
        "   # vgg_optimizer = loss.get_optimizer()\n",
        "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "    \n",
        "    \n",
        "    gan = get_gan_network(discriminator, image_SR_shape, generator, optimizer, loss.vgg_loss)\n",
        "    datagenObj = datagen(batch_count,train_HR,filePath_train_HR)\n",
        "    \n",
        "    \n",
        "    for e in range(1,no_of_epoch):\n",
        "        if e%100==0:\n",
        "            print(e)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            lr_img,hr_img = next(datagenObj)\n",
        "            fake_img = generator.predict(lr_img)\n",
        "            \n",
        "            #inputDisc = np.concatenate([hr_img,fake_img])\n",
        "            \n",
        "            real_data_Y = np.ones(batch_count) - np.random.random_sample(batch_count)*0.2\n",
        "            fake_data_Y = np.random.random_sample(batch_count)*0.2\n",
        "            \n",
        "            # training the disciminator\n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            d_loss_real = discriminator.train_on_batch(hr_img, real_data_Y)\n",
        "            d_loss_fake = discriminator.train_on_batch(fake_img, fake_data_Y)\n",
        "            dloss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "           # dloss = discriminator.train_on_batch(inputDisc, target_value)\n",
        "            \n",
        "            #training the generator\n",
        "            #generator is frozen\n",
        "            lr_img,hr_img = next(datagenObj)\n",
        "            target_value = np.ones(batch_count)\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(lr_img, [hr_img,target_value])\n",
        "        \n",
        "        d_loss.append(dloss)\n",
        "        g_loss.append(gan_loss)\n",
        "        \n",
        "        if e == 1 or e % 100 == 0:\n",
        "            saveModels(e,generator,discriminator)\n",
        "            plotGeneratedImages(e,datagenObj,generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYZkpowt2H8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlT069WnHq17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(g_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzFZ4fykk66q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(d_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bXyPT9ClARz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}